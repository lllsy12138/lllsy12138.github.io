---
layout: post
title: "VAL"
subtitle: 'Image Search with Text Feedback by Visiolinguistic Attention Learning'
author: "shay"
header-img: "img/midnight.jpg"
header-mask: 0.4
tags:
  - smart media
  - paper note
---



# VAL
《Image Search with Text Feedback by Visiolinguistic Attention Learning》是2020年被CVPR收录的一篇论文。主要研究的问题是带文本反馈的图片检索。例如给一张黑色的图片，文本反馈是想要一个粉色的同款。
<center>
<img src="https://i.loli.net/2020/10/12/ChoGeEZ1MJKIRFf.png" alt="1" style="zoom: 50%;" />
</center>
本文更加关注文本反馈，因为文本可以是属性描述，也可以是自然语言表达。

##### 本文作者主要有两点贡献

1. 采用VAL结构。VAL是多重复合的transformer。
2. 采用fashion200k，fashionIQ，shoes三个数据集

<img src="https://i.loli.net/2020/10/13/mKahp4eAoOcQJPX.png" alt="VAL" style="zoom: 33%;" />

##### 图像文本表征
采用标准CNN学习图像表征，从low，mid，high-level 3个level提取，建造一个特征金字塔，表示如下：
<center>
<img src="https://i.loli.net/2020/10/12/bpFEdzUL3tYrNal.png" alt="0" style="zoom:67%;" />
</center>
其中$F_{r}$ 是参考图像，$F_{t}$是目标图像。

采用LTSM来学习文本表征，在LSTM后加入max-pooling和linear projection layer。

### 复合transformer

将文本表征与图像表征融合表示：
<center>
<img src="https://i.loli.net/2020/10/12/onymBkMexOtLWZc.png" alt="2" style="zoom:67%;" />
</center>
其中$i$表示第$i$个图像level，$F_{c}$是MLP

##### 自注意力transformation
<center>
<img src="https://i.loli.net/2020/10/13/yzNbFv9xVR1eHrK.png" alt="3" style="zoom: 50%;" />
<img src="https://i.loli.net/2020/10/13/HSDyXOh5YelpvVu.png" alt="self-attention" style="zoom:50%;" />
<img src="https://i.loli.net/2020/10/13/6tZe1k3OK5qiaD4.png" alt="4" style="zoom: 50%;" />
<img src="https://i.loli.net/2020/10/13/2TfPIscL5FbrwxX.png" alt="5" style="zoom: 50%;" />
</center>

第二个表达式即self-attention函数，第三个表达式计算output

##### Joint-Attentional Preservation

自注意力transformation捕获了用于特征变换的非局部相关性，但是没有确切表明参考图像特征如何保持与输入图像的的相似性。因此引入Joint-Attentional Preservation
<center>
<img src="https://i.loli.net/2020/10/13/5qzA4Ek8TexRm2D.png" alt="6" style="zoom:50%;" />
</center>

$F_{sp}$,$F_{ch}$学习空间和通道。

$A^{i}_{ja}$是joint-attention 矩阵，动态调整保留参考图像的强度。
<center>
<img src="https://i.loli.net/2020/10/13/2XSsuk7JeHFmbMO.png" alt="7" style="zoom:50%;" />
</center>
最终的输出表达时如下：
<center>
<img src="https://i.loli.net/2020/10/13/q7FHXT92eshfwvy.png" alt="8" style="zoom:50%;" />
</center>

##### 分层匹配
采用两种损失，两级层次，分别计算图像和图像，图像和语义的损失

确保目标特征和复合特征的高相似度，采用图像与图像损失表达式如下：

<center>
<img src="https://i.loli.net/2020/10/13/WayJVCPuQhw4sUG.png" alt="10" style="zoom:50%;" />
</center>

为了进一步将学习到的表征与期望的语义联系起来，采用辅助的图像与语义损失表达式如下：

<center>
<img src="https://i.loli.net/2020/10/13/u6eGq2tWvlb8FZr.png" alt="11" style="zoom:50%;" />
</center>